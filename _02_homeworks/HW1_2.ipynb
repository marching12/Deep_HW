{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e61b4d616c4cde13"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "img_arr = imageio.imread(os.path.join(os.path.pardir, \"_00_data\", \"a_image-dog\", \"bobby.jpg\")) #파일열기\n",
    "\n",
    "print(type(img_arr))  # 이미지 배열의 데이터 타입 출력\n",
    "print(img_arr.shape)  # 이미지의 형태 출력\n",
    "print(img_arr.dtype)  # 이미지의 데이터 타입 출력\n",
    "\n",
    "img = torch.from_numpy(img_arr) # numpy 배열을 PyTorch 텐서로 변환\n",
    "out = img.permute(2, 0, 1)  # 이미지의 차원을 (높이, 너비, 채널)에서 (채널, 높이, 너비)로 변환\n",
    "print(out.shape)  \n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "data_dir = os.path.join(os.path.pardir, \"_00_data\", \"b_image-cats\")\n",
    "\n",
    "# 해당 디렉토리 내에 있는 .png 확장자의 파일명을 가져옴\n",
    "filenames = [\n",
    "  name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png'\n",
    "]\n",
    "print(filenames)\n",
    "\n",
    "\n",
    "# 각 파일을 열어서 이미지 출력 및 정보 출력\n",
    "for i, filename in enumerate(filenames):\n",
    "  image = Image.open(os.path.join(data_dir, filename))\n",
    "  image.show()\n",
    "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "  print(img_arr.shape)\n",
    "  print(img_arr.dtype)\n",
    "\n",
    "batch_size = 3  # 배치 사이즈 설정 \n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8) # (배치, 채널, 높이, 너비)의 빈 텐서 생성\n",
    "\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "  img_t = torch.from_numpy(img_arr)\n",
    "  img_t = img_t.permute(2, 0, 1)\n",
    "  batch[i] = img_t  # 변환된 텐서를 배치에 추가\n",
    "\n",
    "print(batch.shape)  # 배치 텐서의 크기 출력\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "batch = batch.float()\n",
    "batch /= 255.0  #이미지값을 0~1로 정규화\n",
    "print(batch.dtype)\n",
    "print(batch.shape)\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "\n",
    "for c in range(n_channels):\n",
    "  mean = torch.mean(batch[:, c])\n",
    "  std = torch.std(batch[:, c])\n",
    "  print(mean, std)\n",
    "  batch[:, c] = (batch[:, c] - mean) / std"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# A 고찰내용\n",
    "#### 이미지 데이터 확인 및 출력\n",
    "1. 이미지 파일을 텐서로 관리할 수 있다.\n",
    "2. 텐서 차원의 순서를 변경할 수 있다.\n",
    "3. 정규화를 할 수 있다."
   ],
   "id": "3efe0a1640469178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "# DICOM 볼륨 데이터가 있는 디렉토리 경로 설정\n",
    "dir_path = os.path.join(os.path.pardir, \"_00_data\", \"c_volumetric-dicom\", \"2-LUNG_3.0_B70f-04083\")  # 파일 경로 코드 수정\n",
    "# DICOM 볼륨 데이터를 읽어 numpy 배열로 변환\n",
    "vol_array = imageio.volread(dir_path, format='DICOM')\n",
    "print(type(vol_array))   # >>> <class 'imageio.core.util.Array'>:  Numpy NDArray\n",
    "# 이는 99개의 슬라이스(slice)로 구성된 512x512 크기의 3D 이미지임을 의미함\n",
    "print(vol_array.shape)   # >>> (99, 512, 512)\n",
    "# vol_array의 데이터 타입 출력: DICOM 이미지 파일에서 추출된 int16 데이터 타입\n",
    "print(vol_array.dtype)   # >>> int16\n",
    "print(vol_array[0])\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for id in range(0, 99):\n",
    "  fig.add_subplot(10, 10, id + 1)\n",
    "  plt.imshow(vol_array[id])\n",
    "plt.show()  # 전체 슬라이스 이미지들을 한 번에 표시\n",
    "\n",
    "import torch\n",
    "# numpy 배열을 PyTorch 텐서로 변환하고, float 타입으로 변환\n",
    "vol = torch.from_numpy(vol_array).float()\n",
    "# 첫 번째 차원에 채널 차원을 추가 (예: [C, D, H, W] 형태로 만듦)\n",
    "vol = torch.unsqueeze(vol, 0)  # channel\n",
    "# 두 번째 차원에 데이터 차원을 추가하여 [B, C, D, H, W] 형태로 만듦\n",
    "vol = torch.unsqueeze(vol, 0)  # data size\n",
    "\n",
    "print(vol.shape)  # >>> torch.Size([1, 1, 99, 512, 512])\n",
    "  \n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "mean = torch.mean(vol, dim=(3, 4), keepdim=True)  # mean over all of dim=(3, 4)\n",
    "print(mean.shape)\n",
    "std = torch.std(vol, dim=(3, 4), keepdim=True)    # std over all of dim=(3, 4)\n",
    "print(std.shape)\n",
    "vol = (vol - mean) / std\n",
    "print(vol.shape)\n",
    "\n",
    "print(vol[0, 0, 0])  "
   ],
   "id": "60a1df99f1ba0926",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# B 고찰내용\n",
    "1. DICOM 데이터의 읽기 및 numpy 배열 변환을 할 수 있다.\n",
    "2. 데이터 형태 및 타입 확인할 수 있다.\n",
    "3. 이미지 시각화를 할 수 있다.\n",
    "4. numpy를 텐서로 변환할 수 있다.\n",
    "5. 정규화를 할 수 있다.\n",
    "6. 3D 볼륨 데이터에서 특정 슬라이스에 접근할 수 있다."
   ],
   "id": "627ce1ade69f5125"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "wine_path = os.path.join(os.path.pardir, \"_00_data\", \"d_tabular-wine\", \"winequality-white.csv\")\n",
    "# 데이터를 NumPy 배열로 로드 (헤더를 건너뛰고, ';'로 구분된 값)\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "print(wineq_numpy.dtype)\n",
    "print(wineq_numpy.shape)\n",
    "print(wineq_numpy)\n",
    "print()\n",
    "# CSV 파일에서 컬럼 목록 읽기\n",
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "print(col_list)\n",
    "print()\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "import torch\n",
    "# NumPy 배열을 PyTorch 텐서로 변환\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "print(wineq.dtype)\n",
    "print(wineq.shape)\n",
    "print()\n",
    "\n",
    "# 특성과 타겟을 분리\n",
    "data = wineq[:, :-1]  # Selects all rows and all columns except the last\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "target = wineq[:, -1]  # Selects all rows and the last column\n",
    "print(target.dtype)\n",
    "print(target.shape)\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "target = target.long()  # treat labels as an integer\n",
    "print(target.dtype)\n",
    "print(target.shape)\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "# 원-핫 인코딩을 위한 단위 행렬 생성\n",
    "eye_matrix = torch.eye(10)\n",
    "# We use the 'target' tensor as indices to extract the corresponding rows from the identity matrix\n",
    "# It can generate the one-hot vectors for each element in the 'target' tensor\n",
    "onehot_target = eye_matrix[target]\n",
    "\n",
    "print(onehot_target.shape)  # >>> torch.Size([4898, 10])\n",
    "print(onehot_target[0])\n",
    "print(onehot_target[1])\n",
    "print(onehot_target[-2])\n",
    "print(onehot_target)\n",
    "\n",
    "print(\"#\" * 50, 3)\n",
    "# 데이터 정규화\n",
    "data_mean = torch.mean(data, dim=0)\n",
    "data_var = torch.var(data, dim=0)\n",
    "data = (data - data_mean) / torch.sqrt(data_var)\n",
    "print(data)\n",
    "\n",
    "print(\"#\" * 50, 4)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 분할: 훈련 세트와 검증 세트\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, onehot_target, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "def get_wine_data():  #함수화\n",
    "  # 데이터 로드 및 전처리 함수 정의\n",
    "  wine_path = os.path.join(os.path.pardir, os.path.pardir, \"_00_data\", \"d_tabular-wine\", \"winequality-white.csv\")\n",
    "  wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "  \n",
    "  # NumPy 배열을 PyTorch 텐서로 변환\n",
    "  wineq = torch.from_numpy(wineq_numpy)\n",
    "  # 특성과 타겟을 분리\n",
    "  data = wineq[:, :-1]  # Selects all rows and all columns except the last\n",
    "  target = wineq[:, -1].long()  # treat labels as an integer\n",
    "  # 원-핫 인코딩\n",
    "  eye_matrix = torch.eye(10)\n",
    "  onehot_target = eye_matrix[target]\n",
    "  # 데이터 정규화\n",
    "  data_mean = torch.mean(data, dim=0)\n",
    "  data_var = torch.var(data, dim=0)\n",
    "  data = (data - data_mean) / torch.sqrt(data_var)\n",
    "\n",
    "  X_train, X_valid, y_train, y_valid = train_test_split(data, onehot_target, test_size=0.2)\n",
    "\n",
    "  return X_train, X_valid, y_train, y_valid"
   ],
   "id": "56b5f0abf8afbd38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# C 고찰내용\n",
    "1. csv 파일을 읽고 로드할 수 있다.\n",
    "2. 타겟을 정수형으로 변환하고 원 핫 인코딩 후 정규화할 수 있다.\n",
    "* 원 핫 인코딩은 보통 범주형 데이터를 수치형으로 바꿀 때 사용한다.\n",
    "3. 데이터분할이 가능하다.\n",
    "4. 함수화하여 사용 가능하다."
   ],
   "id": "33e2d1390166ea4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://medium.com/analytics-vidhya/implement-linear-regression-on-boston-housing-dataset-by-pytorch-c5d29546f938\n",
    "# https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n",
    "import torch\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# California Housing 데이터셋을 로드합니다.\n",
    "housing = fetch_california_housing()\n",
    "print(housing.keys()) # 데이터셋의 키를 출력하여 어떤 정보가 포함되어 있는지 확인합니다.\n",
    "\n",
    "# 데이터와 관련된 정보 출력\n",
    "print(type(housing.data))  # 데이터 타입 확인 (일반적으로 <class 'numpy.ndarray'>)\n",
    "print(housing.data.dtype)  # 데이터의 타입 확인 (예: float64)\n",
    "print(housing.data.shape)  # 데이터 배열의 형태 확인 (예: (20640, 8))\n",
    "print(housing.feature_names)  # 데이터의 특성 이름 출력\n",
    "\n",
    "print(housing.target.shape)  # 타겟 배열의 형태 확인 (예: (20640,))\n",
    "print(housing.target_names)  # 타겟의 이름 출력 (California Housing 데이터는 타겟 이름이 없음)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(housing.data.min(), housing.data.max())\n",
    "#정규화\n",
    "data_mean = np.mean(housing.data, axis=0)\n",
    "data_var = np.var(housing.data, axis=0)\n",
    "data = (housing.data - data_mean) / np.sqrt(data_var)\n",
    "target = housing.target\n",
    "\n",
    "\n",
    "print(data.min(), data.max()) # 정규화된 데이터 최소값과 최대값을 출력하여 정규화 확인.\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터를 훈련 세트와 테스트 세트로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터의 형태를 출력하여 확인합니다.\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "id": "83d90860ded12bcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# D 고찰내용\n",
    "1. fetch_california_housing() 함수를 통해 California Housing 데이터셋을 로드할 수 있다.\n",
    "2. 정규화의 필요성\n",
    "* 데이터의 범위가 서로 다를 경우, 모델학습의 성능을 향상시키기 위해 정규화가 필요하다.\n",
    "* 방법 : 평균과 분산계산 ->  정규화 적용 -> 정규화 확인\n",
    "3. 훈련 및 테스트 데이터로 분할 한다.\n",
    "* 모델의 일반화 성능 평가와 과적합 방지를 위해 분할한다. \n",
    "4. 훈련데이터와 테스트 데이터의 형태를 출력하여 검사할 필요가 있다."
   ],
   "id": "f1fbbd17a7ce6d34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, threshold=50, linewidth=75) # PyTorch의 출력 옵션 설정: 배열의 끝부분을 2개 항목만 표시하고, 전체 출력 개수 제한\n",
    "\n",
    "bikes_path = os.path.join(os.path.pardir, \"_00_data\", \"e_time-series-bike-sharing-dataset\", \"hour-fixed.csv\")\n",
    "\n",
    "bikes_numpy = np.loadtxt(   # CSV 파일에서 데이터를 NumPy 배열로 로드\n",
    "  fname=bikes_path, dtype=np.float32, delimiter=\",\", skiprows=1,\n",
    "  converters={\n",
    "    1: lambda x: float(x[8:10])  # 2011-01-07 --> 07 --> 7.0\n",
    "  }\n",
    ")\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "print(bikes.shape)\n",
    "\n",
    "# 데이터를 하루 단위로 재구성 (730일, 24시간, 17개의 특성)\n",
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "print(daily_bikes.shape)  # >>> torch.Size([730, 24, 17])\n",
    "# 특성과 타겟을 분리\n",
    "daily_bikes_data = daily_bikes[:, :, :-1]\n",
    "daily_bikes_target = daily_bikes[:, :, -1].unsqueeze(dim=-1)\n",
    "\n",
    "print(daily_bikes_data.shape)\n",
    "print(daily_bikes_target.shape)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "# 첫 번째 날의 데이터 추출\n",
    "first_day_data = daily_bikes_data[0]\n",
    "print(first_day_data.shape)\n",
    "\n",
    "# 날씨 상황 열을 정수형으로 출력\n",
    "print(first_day_data[:, 9].long())\n",
    "# 날씨 상황을 원-핫 인코딩하기 위한 단위 행렬 생성\n",
    "eye_matrix = torch.eye(4)\n",
    "print(eye_matrix)\n",
    "\n",
    "# 날씨 상황 열을 원-핫 인코딩\n",
    "weather_onehot = eye_matrix[first_day_data[:, 9].long() - 1]\n",
    "print(weather_onehot.shape)\n",
    "print(weather_onehot)\n",
    "\n",
    "# 원-핫 인코딩된 날씨 데이터를 기존의 데이터와 연결\n",
    "first_day_data_torch = torch.cat(tensors=(first_day_data, weather_onehot), dim=1)\n",
    "print(first_day_data_torch.shape)\n",
    "print(first_day_data_torch)\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "# 모든 날에 대해 날씨 상황을 원-핫 인코딩하고, 기존 데이터와 연결\n",
    "day_data_torch_list = []\n",
    "\n",
    "for daily_idx in range(daily_bikes_data.shape[0]):  # range(730)\n",
    "  day = daily_bikes_data[daily_idx]  # day.shape: [24, 16]\n",
    "  weather_onehot = eye_matrix[day[:, 9].long() - 1]\n",
    "  day_data_torch = torch.cat(tensors=(day, weather_onehot), dim=1)  # day_data_torch.shape: [24, 20]\n",
    "  day_data_torch_list.append(day_data_torch)\n",
    "\n",
    "print(len(day_data_torch_list))\n",
    "daily_bikes_data = torch.stack(day_data_torch_list, dim=0)\n",
    "print(daily_bikes_data.shape)\n",
    "\n",
    "print(\"#\" * 50, 3)\n",
    "# 데이터에서 'instant'와 'wheathersit' 열을 제거하고 나머지 열을 사용\n",
    "print(daily_bikes_data[:, :, :9].shape, daily_bikes_data[:, :, 10:].shape)\n",
    "daily_bikes_data = torch.cat(\n",
    "  [daily_bikes_data[:, :, 1:9], daily_bikes_data[:, :, 10:]], dim=2\n",
    ") # Drop 'instant' and 'whethersit' columns\n",
    "print(daily_bikes_data.shape)\n",
    "\n",
    "# 온도 열을 정규화 (평균이 0, 표준편차가 1이 되도록 변환)\n",
    "temperatures = daily_bikes_data[:, :, 8]\n",
    "daily_bikes_data[:, :, 8] = (daily_bikes_data[:, :, 8] - torch.mean(temperatures)) / torch.std(temperatures)\n"
   ],
   "id": "6cd52369fe991a9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# E 고찰 내용\n",
    "1. 데이터 재구성\n",
    "* bikes.view(-1, 24, bikes.shape[1])로 데이터셋을 하루단위로 재구성할 수 있다.\n",
    "* 특성과 타겟을 분리하고 나머지 열을 특성으로 사용가능하다.\n",
    "2. 원 핫 인코딩\n",
    "* torch.eye(4)를 통해 단위 행렬을 생성할 수 있다.\n",
    "* eye_matrix[first_day_data[:, 9].long() - 1]를 통해 날씨 상황 열을 원-핫 인코딩하여 범주형 변수를 수치형 벡터로 변환할 수 있다.\n",
    "* torch.cat()로 기존 데이터와 원 핫 인코딩된 데이터를 합칠 수 있다.\n",
    "3. 데이터 정리 및 처리\n",
    "* 모든 날의 데이터를 리스트로 저장하고, torch.stack를 사용하여 텐서로 변환할 수 있다.\n",
    "* torch.cat를 사용하여 불필요한 열을 제거할 수 있다."
   ],
   "id": "832628d2e471f3d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d5e5b862a8cf0ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
